{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694ba110",
   "metadata": {},
   "source": [
    "# Familiarity Rating Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf615f-dc38-45e9-8275-046ab609866b",
   "metadata": {},
   "source": [
    "##### **【⚠️Note】** APIs and models evolve rapidly. This code reflects the API methods available at the time of the study. \n",
    "##### Please consult official documentation for the latest API protocols and parameter settings before extending this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bae44b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc65c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Configuration\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb6d7e-6f5d-4f1c-bc17-bc00cb836aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "# Replace 'sk-xxxxxx' with your actual OpenAI API key\n",
    "API_KEY = \"sk-xxxxxx\" \n",
    "MODEL_NAME = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988b5d2-c7af-4572-aac2-a21c1a5dbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "INPUT_FILE = \"./target_words.txt\"      # Path to the input text file containing cues\n",
    "OUTPUT_PKL = \"GPT_familiar_results.pkl\"  # Path to save results as a pickle file\n",
    "OUTPUT_LOG = \"GPT_familiar_results.txt\"  # Path to save results as a text log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac2af1-8bb9-4c3a-8275-25e9b6a18ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Generation Parameters\n",
    "GPT_PARAMS = {\n",
    "    \"temperature\": 0,       # 0-2\n",
    "    \"max_tokens\": 10,       # Max tokens for response\n",
    "    \"top_logprobs\": 7,      # Return top 7 log probabilities for research analysis\n",
    "    \"logprobs\": True        # Explicitly enable logprobs return\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939151d5-39cf-4feb-a8cc-e8970ba7d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Settings\n",
    "REPEAT_TIMES = 1        # Number of times to repeat the entire cue list\n",
    "MAX_REQUESTS = 780000   # Safety limit for total API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3db66-d5a2-4bb7-86b1-4be6dec7c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Client\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the cue words\n",
    "def load_cues(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        # Read lines, strip whitespace, and keep only non-empty lines\n",
    "        cues = [line.strip() for line in file if line.strip()]\n",
    "    print(f\"Successfully loaded {len(cues)} unique cues.\")\n",
    "    return cues\n",
    "\n",
    "CUES = load_cues(INPUT_FILE)\n",
    "print(f\"Preview: {CUES[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e7e69-1543-4566-ac61-aac079704cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize items in the CUES\n",
    "def randomize_cues(cues, repeat=1):\n",
    "    final_sequence = []\n",
    "    for i in range(repeat):\n",
    "        batch = cues.copy()\n",
    "        random.shuffle(batch)\n",
    "        final_sequence.extend(batch)\n",
    "    print(f\"Randomization complete. Total trials generated: {len(final_sequence)}\")\n",
    "    return final_sequence\n",
    "\n",
    "CUES_ALL = randomize_cues(CUES, repeat=REPEAT_TIMES)\n",
    "print(f\"Final Sequence Preview: {CUES_ALL[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9745c04-c429-4e08-a9e5-419e4d39cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Interaction Function\n",
    "\n",
    "def get_gpt_rating(cue, client, model, params):\n",
    "    prompt_text = (\n",
    "        \"Complete the following tasks as a native speaker of Simplified Chinese: \"\n",
    "        \"Familiarity is a measure of how familiar something is. \"\n",
    "        \"A Chinese word is very FAMILIAR if you see/hear it often and it is easily recognisable. \"\n",
    "        \"In contrast, a Chinese word is very UNFAMILIAR if you rarely see/hear it and it is relatively unrecognisable. \"\n",
    "        \"Please indicate how familiar you think each Chinese word is on a scale from 1 (VERY UNFAMILIAR) to 7 (VERY FAMILIAR), \"\n",
    "        \"with the midpoint representing moderate familiarity. \"\n",
    "        f\"The Chinese word is: {cue} \" \n",
    "        \" Only answer a number from 1 to 7. Please limit your answer to numbers.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "\n",
    "    try:\n",
    "        # Call API \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=params[\"temperature\"],   \n",
    "            max_tokens=params[\"max_tokens\"],     \n",
    "            top_logprobs=params[\"top_logprobs\"], \n",
    "            logprobs=params[\"logprobs\"]         \n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content.strip()\n",
    "        logprobs_data = response.choices[0].logprobs.content\n",
    "        \n",
    "        logprobs_formatted = \"\"\n",
    "        if logprobs_data:\n",
    "            for token_info in logprobs_data:\n",
    "                entry = \", \".join([f\"'{t.token}': {t.logprob}\" for t in token_info.top_logprobs])\n",
    "                logprobs_formatted += f\"{entry}\\n\"\n",
    "\n",
    "        return {\n",
    "            \"cue\": cue,\n",
    "            \"rating\": content,\n",
    "            \"raw_logprobs\": logprobs_data,     \n",
    "            \"formatted_logprobs\": logprobs_formatted \n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing cue '{cue}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad6415-f939-4249-84f9-43adc72c724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting experiment on {len(CUES_ALL)} items... \")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9772cd9-2145-4b8a-b43f-36c15aa66230",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_buffer = []  \n",
    "\n",
    "# Loop through all cues \n",
    "for index, cue in enumerate(CUES_ALL):\n",
    "    \n",
    "    # Safety break \n",
    "    if index >= MAX_REQUESTS:\n",
    "        print(\"Reached maximum request limit. \")\n",
    "        break\n",
    "        \n",
    "    result = get_gpt_rating(\n",
    "        cue=cue, \n",
    "        client=client, \n",
    "        model=MODEL_NAME, \n",
    "        params=GPT_PARAMS \n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        results_buffer.append(result)\n",
    "        \n",
    "        # Write to Text Log \n",
    "        with open(OUTPUT_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{result['cue']}，，，\\n\")\n",
    "            f.write(f\"{result['rating']}。。。\\n\")\n",
    "            f.write(result['formatted_logprobs'])\n",
    "            f.write(\"\\n\") \n",
    "            \n",
    "        print(f\"[{index+1}/{len(CUES_ALL)}] {cue} -> {result['rating']}\")\n",
    "        \n",
    "    # Save Checkpoint (Every 10 items) \n",
    "    if (index + 1) % 10 == 0:\n",
    "        with open(OUTPUT_PKL, \"wb\") as f:\n",
    "            pickle.dump(results_buffer, f)\n",
    "        print(\" Checkpoint saved.\")\n",
    "\n",
    "# Final Save \n",
    "with open(OUTPUT_PKL, \"wb\") as f:\n",
    "    pickle.dump(results_buffer, f)\n",
    "\n",
    "print(\"\\n Experiment finished! All data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014c464",
   "metadata": {},
   "source": [
    "### Qwen-max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd840fbf-52c2-46f8-a5c9-17f764df8b18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **【⚠️Note】**  At the time of this study, the official Qwen model API did not provide log probability parameters. \n",
    "##### Therefore, we queried the model 30 times for each word and calculated the average to obtain the rating for each word. \n",
    "##### Currently, the Qwen model supports log probability parameters; please refer to the official documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Configuration\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067810a-051f-47a7-99ee-27e4c3d3f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_KEY = \"sk-xxxxxx\" # Replace with your actual Qwen API Key\n",
    "BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "MODEL_NAME = \"qwen-max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f30a1e-347c-4fc1-ab95-bcd4ba02913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "INPUT_FILE = \"./target_words.txt\"        # Path to the input text file containing cues\n",
    "OUTPUT_PKL = \"Qwen_familiar_results.pkl\" # Path to save results as a pickle file\n",
    "OUTPUT_LOG = \"Qwen_familiar_results.txt\" # Path to save results as a text log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba2605-3404-4a15-8710-0aad0415905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Parameters \n",
    "GEN_PARAMS = {\n",
    "    \"temperature\": 0.7,     \n",
    "    \"max_tokens\": 100,      # Max tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297aa7a-1f85-4f15-b430-2de66cd9501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Control\n",
    "REPEAT_TIMES = 30       \n",
    "MAX_REQUESTS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02178cd-d6b8-4e83-9052-51f9e62f9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Client\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "print(f\"✅ Configuration loaded. Plan: Repeat {REPEAT_TIMES} times per cue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4a1db-45d2-4556-8523-becc4de9054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the cue words\n",
    "def load_cues(filepath):\n",
    "    \"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        # Read lines, strip whitespace, and keep only non-empty lines\n",
    "        cues = [line.strip() for line in file if line.strip()]\n",
    "        \n",
    "    print(f\"Successfully loaded {len(cues)} unique cues.\")\n",
    "    return cues\n",
    "\n",
    "CUES = load_cues(INPUT_FILE)\n",
    "print(f\"Preview: {CUES[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07313e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomize items in the CUES\n",
    "def randomize_cues(cues, repeat=1):\n",
    "    final_sequence = []\n",
    "    for i in range(repeat):\n",
    "        batch = cues.copy()\n",
    "        random.shuffle(batch)\n",
    "        final_sequence.extend(batch)\n",
    "        \n",
    "        # Print progress every 5 repeats to show it's working \n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"  -> {i+1} / {repeat} batches added.\")\n",
    "        \n",
    "    print(f\"Randomization complete. Total trials generated: {len(final_sequence)}\")\n",
    "    return final_sequence\n",
    "\n",
    "\n",
    "CUES_ALL = randomize_cues(CUES, repeat=REPEAT_TIMES)\n",
    "print(f\"Final Sequence Preview: {CUES_ALL[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccd777-e8a6-4c09-b2b9-c1b3d9439ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen Interaction Function\n",
    "\n",
    "def get_qwen_rating(cue, client, model, params):\n",
    "    \n",
    "    prompt_text = (\n",
    "        \"作为一个简体中文母语者完成以下任务：熟悉度是衡量某个东西对你来说有多熟悉的测量标准。\"\n",
    "        \"如果一个中文词或者汉字是你经常看到或听到的，并且很容易认出来，那么它就是非常熟悉的。\"\n",
    "        \"相反，如果一个中文词或者汉字是你很少看到或听到的，并且不太容易认出来，那么它就是非常不熟悉的。\"\n",
    "        \"请在1（非常不熟悉）到7（非常熟悉）的范围内，评估每个中文词或者汉字在你看来有多熟悉，其中的中点代表适中的熟悉度。\"\n",
    "        f\"这一个中文词或者汉字是：{cue}\"\n",
    "        \"请只回答一个从1到7的数字，并确保答案仅限于数字。\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=params[\"temperature\"],   \n",
    "            max_tokens=params[\"max_tokens\"]\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        return {\n",
    "            \"cue\": cue,\n",
    "            \"rating\": content,\n",
    "            \"response_obj\": response \n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing cue '{cue}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a92572-8a86-4853-afee-ea462065ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting experiment on {len(CUES_ALL)} items...\")\n",
    "print(f\"Model: {MODEL_NAME} | Repeats: {REPEAT_TIMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18eb86-168d-4769-a730-df8bf4ccca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_buffer = []  \n",
    "\n",
    "# Loop through all cues\n",
    "for index, cue in enumerate(CUES_ALL):\n",
    "    \n",
    "    if index >= MAX_REQUESTS:\n",
    "        print(\"Reached maximum request limit.\")\n",
    "        break\n",
    "        \n",
    "    result = get_qwen_rating(\n",
    "        cue=cue, \n",
    "        client=client, \n",
    "        model=MODEL_NAME, \n",
    "        params=GEN_PARAMS \n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        results_buffer.append(result)\n",
    "        \n",
    "        with open(OUTPUT_LOG, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{result['cue']}，，，\\n\")\n",
    "            f.write(f\"{result['rating']}。。。\\n\")\n",
    "            f.write(\"\\n\") \n",
    "            \n",
    "        print(f\"[{index+1}/{len(CUES_ALL)}] {cue} -> {result['rating']}\")\n",
    "        \n",
    "    if (index + 1) % 20 == 0:\n",
    "        with open(OUTPUT_PKL, \"wb\") as f:\n",
    "            pickle.dump(results_buffer, f)\n",
    "        print(\" Checkpoint saved.\")\n",
    "    \n",
    "    # Sleep 0.3s to respect Qwen API limits \n",
    "    time.sleep(0.3) \n",
    "\n",
    "with open(OUTPUT_PKL, \"wb\") as f:\n",
    "    pickle.dump(results_buffer, f)\n",
    "\n",
    "print(\"\\n Qwen Experiment finished! All data saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
